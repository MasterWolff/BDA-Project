24/03/2022: (Klaus) 
    Updated remove_redundancies(df_name) 
        defined df_new as dropping the columns from the dataframe defined in the parameter "df_name". 
        The columns dropped are defined in the list redundant_columns.

24/03/2022: (Mads)
    Updated remove_redundancies(df_name)
        Though it looked to be working in Klaus' iteration, the result of the function was not being correctly saved
        and calling upon 'df' later would just call on the imported version, not the processed one.

    Started removing index column <-- Work in Progress
        When using the pd.read_csv() function, a new column is created that cannot be called upon, this is the index column
        and is what I am trying to remove. Though it is not directly influencing our data or the way we wish to progress 
        with our machine learning, it is just quite cluttered to look at because we have so many rows. I've not yet figured
        out how to make it work correctly, I can remove the index column during import, but then the 'id' column takes its
        place and creates a whole new slew of problems. for now they are muted as they influence the other code, feel free
        to fix if you want, I will try to fix at a later date if not resolved by then.

    Started importing for ML + TTS
        Imported train test split (TTS) and performed this on the data, considering the target value to be the
        'stop_outcome' column, and the data to be the rest.

27/03/2022: (Mads)
    Get dummies
        Created dummy values for all of the columns which contained non-numerical values, spoiler alert it was all of them.
        In total, 523 columns were added.

    Remove NaN values 
        Removed any NaN values present in the 'stop_outcome' column as the target value is always needed in order to create
        a prediction. The same was done for Xd (Xdummy) to remove any NaN values, but none were present.

    Created random forest classifier
        To test the getdummies, I created a basic random forest classifier and only tested it once, reason being that it
        took almost 34 minutes to do so, and returned the same values for train and test, so whether or not they are correct
        is also unlikely. Perhaps someone knows of a way to optimize this? maybe our professor if not one of us?

28/03/2022: (Mads)
    Dataset downsize for testing
        created a copy of the dataframe using the first 100000 rows, this referred to as 'df_testing' reduces run time of 
        analysis by like 1000000%
    Testing parameters 
        testing different values for the max_depth parameter in the random forest, see test_parameter function
    WIP: Test parameters function
        began creating a version where the parameters you wish to test and the values with which you want to test them can 
        be selected, currently not working, might also not be necessary, just makes it easier to test them.

30/03/2022 (Mads)
    Visualizing driver race distribution

31/03/2022 (Mads)
    Improving data visualisation of driver race, that's it.

1/04/2022 (Mads)
    RandomForestClassifier parameter optimisation
	    Added a couple lines of code sourced from here: 
        https://www.kaggle.com/code/funxexcel/p3-random-forest-tuning-randomizedsearchcv/notebook that is able to test all
        the different combinations of parameter values and identify the ones which yield the most accurate results. Worth it?
        fuck no. it took 54 minutes for the code to run only for it to result in an accuracy score that was only 0.004 higher
        than when I just tested random numbers for the max_depth parameter. unsure if it is worth testing it again with another
        framework, using randomized search CV instead of the Grid search CV that I used this time? In any case I think it's
        worth noting in our report, perhaps in an appendix or something, but definitely not worth doing for the other models
        we intend to do. pro strat --> dont run all cells because it will take an hour in total (at least on my computer so
        god knows how long it will take for whoever else might make the mistake of optimizing the parameters).

6/04/2022
    KNN and KNN parameter optimization
        I added in a KNN model for the data, and did some parameter optimization, took 262 minutes to do but I anticipated
        that and left it over night because big brain :) it is however a little suspicious that the random forest got the same
        accuracy as the KNN, however it doesnt seem as though there is an issue with the code? so it might just be a coincidence
        I'll redo the random forest overnight because there was an error last time with one of the data values, just to check!

26/04/2022
    parameter optimization:
        I added the third model we use, which is the GradientBoostingClassifier(), and optimized its parameters
    feature importance visualisation:
        Started trying to identify and plot the feature importance for the different models, to see what has the largest influence on the outcome, fx. driver race
    code cleanup:
        Removing old versions of code and redundant code blocks, added titles above each block that signify what they do.
        